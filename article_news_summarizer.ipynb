{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1qikMuvZBhE",
        "outputId": "562c3b21-a871-4aa5-d822-69b0dacd9e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "5QpIz9AKZI3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "AsBBXMERZijT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --quiet langchain-google-genai  langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW2MMlm9Zjii",
        "outputId": "8bbb4baa-3293-4890-ad22-ab609bd674a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/817.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/817.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m716.8/817.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "jhDSrA_VbWRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature=0.3,google_api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "0LMWT-04baxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from newspaper import Article\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
        "}\n",
        "\n",
        "article_urls = \"https://www.artificialintelligence-news.com/2022/01/25/meta-claims-new-ai-supercomputer-will-set-records/\"\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "try:\n",
        "    response = session.get(article_urls, headers=headers, timeout=10)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        article = Article(article_urls)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "\n",
        "        print(f\"Title: {article.title}\")\n",
        "        print(f\"Text: {article.text}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to fetch article at {article_urls}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred while fetching article at {article_urls}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFDfhckfb8Bg",
        "outputId": "fdb4534c-d272-4f2f-f4b3-3b57182a67c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Meta claims its new AI supercomputer will set records\n",
            "Text: Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
            "\n",
            "Meta (formerly Facebook) has unveiled an AI supercomputer that it claims will be the world’s fastest.\n",
            "\n",
            "The supercomputer is called the AI Research SuperCluster (RSC) and is yet to be fully complete. However, Meta’s researchers have already begun using it for training large natural language processing (NLP) and computer vision models.\n",
            "\n",
            "RSC is set to be fully built in mid-2022. Meta says that it will be the fastest in the world once complete and the aim is for it to be capable of training models with trillions of parameters.\n",
            "\n",
            "“We hope RSC will help us build entirely new AI systems that can, for example, power real-time voice translations to large groups of people, each speaking a different language, so they can seamlessly collaborate on a research project or play an AR game together,” wrote Meta in a blog post.\n",
            "\n",
            "“Ultimately, the work done with RSC will pave the way toward building technologies for the next major computing platform — the metaverse, where AI-driven applications and products will play an important role.”\n",
            "\n",
            "For production, Meta expects RSC will be 20x faster than Meta’s current V100-based clusters. RSC is also estimated to be 9x faster at running the NVIDIA Collective Communication Library (NCCL) and 3x faster at training large-scale NLP workflows.\n",
            "\n",
            "A model with tens of billions of parameters can finish training in three weeks compared with nine weeks prior to RSC.\n",
            "\n",
            "Meta says that its previous AI research infrastructure only leveraged open source and other publicly-available datasets. RSC was designed with the security and privacy controls in mind to allow Meta to use real-world examples from its production systems in production training.\n",
            "\n",
            "What this means in practice is that Meta can use RSC to advance research for vital tasks such as identifying harmful content on its platforms—using real data from them.\n",
            "\n",
            "“We believe this is the first time performance, reliability, security, and privacy have been tackled at such a scale,” says Meta.\n",
            "\n",
            "(Image Credit: Meta)\n",
            "\n",
            "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo. The next events in the series will be held in Santa Clara on 11-12 May 2022, Amsterdam on 20-21 September 2022, and London on 1-2 December 2022.\n",
            "\n",
            "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    HumanMessage\n",
        ")\n",
        "\n",
        "# we get the article data from the scraping part\n",
        "article_title = article.title\n",
        "article_text = article.text\n",
        "\n",
        "# prepare template for prompt\n",
        "template = \"\"\"You are a very good assistant that summarizes online articles.\n",
        "\n",
        "Here's the article you want to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Write a summary of the previous article.\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "messages = [HumanMessage(content=prompt)]"
      ],
      "metadata": {
        "id": "JQIcR1Kiccu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = gemini_llm(messages)\n",
        "print(summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgGufidVcsNH",
        "outputId": "b2865d68-72cc-4e32-dbd0-4f40762f26ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta unveiled its AI supercomputer called AI Research SuperCluster (RSC), which is set to be the world's fastest once completed in mid-2022. The supercomputer is designed for training large natural language processing (NLP) and computer vision models with trillions of parameters. Meta aims to use RSC to develop AI systems for real-time voice translations, AR gaming, and technologies for the metaverse. RSC is expected to be 20x faster than Meta's current V100-based clusters and 9x faster at running the NVIDIA Collective Communication Library (NCCL). It can train models with tens of billions of parameters in three weeks, compared to nine weeks previously. RSC is designed with security and privacy controls to allow Meta to use real-world examples from its production systems in training. Meta believes this is the first time performance, reliability, security, and privacy have been addressed at such a scale.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare template for prompt\n",
        "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists.\n",
        "\n",
        "Here's the article you need to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Now, provide a summarized version of the article in a bulleted list format.\n",
        "\"\"\"\n",
        "\n",
        "# format prompt\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "# generate summary\n",
        "summary = gemini_llm([HumanMessage(content=prompt)])\n",
        "print(summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33bDqUslc6hb",
        "outputId": "a55ddb8c-6757-4822-a80c-a1f9e92f0810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Meta has unveiled an AI supercomputer called the AI Research SuperCluster (RSC), which is set to be the world's fastest once complete in mid-2022.\n",
            "\n",
            "\n",
            "- RSC is designed for training large natural language processing (NLP) and computer vision models with trillions of parameters.\n",
            "\n",
            "\n",
            "- Meta aims to use RSC to develop new AI systems for real-time voice translations, AR gaming, and other metaverse applications.\n",
            "\n",
            "\n",
            "- RSC is expected to be 20x faster than Meta's current V100-based clusters, 9x faster at running the NVIDIA Collective Communication Library (NCCL), and 3x faster at training large-scale NLP workflows.\n",
            "\n",
            "\n",
            "- RSC is designed with security and privacy controls to allow Meta to use real-world examples from its production systems in training, such as identifying harmful content on its platforms.\n",
            "\n",
            "\n",
            "- Meta claims that RSC is the first supercomputer to tackle performance, reliability, security, and privacy at such a scale.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "template = \"\"\"You are an advanced AI assistant that summarizes online articles into bulleted lists in French.\n",
        "\n",
        "Here's the article you need to summarize.\n",
        "\n",
        "==================\n",
        "Title: {article_title}\n",
        "\n",
        "{article_text}\n",
        "==================\n",
        "\n",
        "Now, provide a summarized version of the article in a bulleted list format, in French.\n",
        "\"\"\"\n",
        "\n",
        "prompt = template.format(article_title=article.title, article_text=article.text)\n",
        "\n",
        "summary = gemini_llm([HumanMessage(content=prompt)])\n",
        "print(summary.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH_uucKPdB7m",
        "outputId": "d79cd4b3-7724-4826-96d4-05c75c86638c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Meta (anciennement Facebook) a dévoilé un supercalculateur d'IA qui, selon elle, sera le plus rapide au monde.\n",
            "- Le supercalculateur s'appelle AI Research SuperCluster (RSC) et n'est pas encore complètement terminé.\n",
            "- Les chercheurs de Meta ont déjà commencé à l'utiliser pour entraîner de grands modèles de traitement du langage naturel (NLP) et de vision par ordinateur.\n",
            "- RSC devrait être entièrement construit à la mi-2022.\n",
            "- Meta affirme qu'il sera le plus rapide au monde une fois terminé et qu'il devrait être capable d'entraîner des modèles avec des billions de paramètres.\n",
            "- Meta espère que RSC l'aidera à construire de nouveaux systèmes d'IA qui pourront, par exemple, alimenter des traductions vocales en temps réel pour de grands groupes de personnes, chacune parlant une langue différente, afin qu'elles puissent collaborer de manière transparente à un projet de recherche ou jouer ensemble à un jeu de RA.\n",
            "- RSC permettra de développer des technologies pour la prochaine grande plateforme informatique : le métavers, où les applications et les produits basés sur l'IA joueront un rôle important.\n",
            "- Pour la production, Meta prévoit que RSC sera 20 fois plus rapide que les clusters actuels de Meta basés sur V100.\n",
            "- RSC devrait également être 9 fois plus rapide pour exécuter la bibliothèque de communication collective NVIDIA (NCCL) et 3 fois plus rapide pour entraîner des flux de travail NLP à grande échelle.\n",
            "- Un modèle avec des dizaines de milliards de paramètres peut terminer sa formation en trois semaines, contre neuf semaines avant RSC.\n",
            "- Meta affirme que son infrastructure de recherche en IA précédente ne s'appuyait que sur des sources ouvertes et d'autres ensembles de données accessibles au public.\n",
            "- RSC a été conçu en tenant compte des contrôles de sécurité et de confidentialité afin de permettre à Meta d'utiliser des exemples réels de ses systèmes de production dans la formation à la production.\n",
            "- En pratique, cela signifie que Meta peut utiliser RSC pour faire progresser la recherche sur des tâches essentielles telles que l'identification des contenus préjudiciables sur ses plateformes, en utilisant des données réelles provenant de ces dernières.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zqDU4kndKHv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}